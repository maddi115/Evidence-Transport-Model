# Evidence-Transport-Model


Automatic citation‑aware RAG system: retrieves relevant vectors from a database, auto‑injects them into the LLM prompt 
with source tags, and generates answers with hard‑coded inline citations, ensuring traceable, provenance‑grounded outputs., 
im surprised their isnt a framework where it grabs the embedded models output puts into capsule/vessels then the llm grabs 
that puts that in the output and then the answer reveals itself, ah so the output becomes chunks themselves? right but the 
llm still has too chose what words are the right answer right? so each word becomes a chunk or what?should we design a framework 
to do this or let the LLM do the work remember LLMS can hallucinate.. so the get placed by the ai in the output then it spits 
out finally in the answer do you understand? kinda like how react does and packages stuff want the chunks themselves 
(or at least the content of the capsules) to appear directly in the final answer cited evidence is shown in the final 
answer do you understand? Chunks are  vessels → default, most of the text

Word-level pointers  -> optional, for short, precise answers, so what should describe the words then a capsule 
and the chunk should that be a vessel?  micro-vessel?

---the LLM it should add some acknoledgement here and the make the evidence answer most of it [evidence here] understand? 
